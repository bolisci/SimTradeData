"""
æµ‹è¯•å¢é‡åŒæ­¥å¯¹å†å²æ•°æ®çš„å¤„ç†è¡Œä¸º
éªŒè¯æ˜¯å¦ä¼šé‡æ–°å¤„ç†å·²æœ‰æ•°æ®
"""

from datetime import date

import pytest

from tests.conftest import BaseTestClass, SyncTestMixin


@pytest.mark.sync
@pytest.mark.database
class TestHistoricalDataBehavior(BaseTestClass, SyncTestMixin):
    """æµ‹è¯•å¢é‡åŒæ­¥å¯¹å†å²æ•°æ®çš„å¤„ç†è¡Œä¸º"""

    def test_incremental_sync_historical_behavior(
        self, db_manager, data_source_manager, processing_engine, config
    ):
        """æµ‹è¯•å¢é‡åŒæ­¥å¯¹å†å²æ•°æ®çš„å¤„ç†è¡Œä¸º"""
        from simtradedata.sync import IncrementalSync

        incremental_sync = IncrementalSync(
            db_manager, data_source_manager, processing_engine, config
        )

        # æµ‹è¯•è‚¡ç¥¨
        test_symbol = "000001.SZ"
        target_date = date(2025, 1, 24)

        self.print_test_info(
            "å¢é‡åŒæ­¥å†å²æ•°æ®è¡Œä¸ºæµ‹è¯•", [test_symbol], date(2025, 1, 20), target_date
        )

        # 1. æ£€æŸ¥å½“å‰æ•°æ®çŠ¶æ€
        self._check_current_data_state(db_manager, test_symbol)

        # 2. è·å–æœ€åæ•°æ®æ—¥æœŸ
        last_date = incremental_sync.get_last_data_date(test_symbol, "1d")
        print(f"ğŸ“… æœ€åæ•°æ®æ—¥æœŸ: {last_date}")

        # 3. è®¡ç®—åŒæ­¥èŒƒå›´
        start_date, end_date = incremental_sync.calculate_sync_range(
            test_symbol, target_date, "1d"
        )
        print(f"ğŸ“… è®¡ç®—çš„åŒæ­¥èŒƒå›´: {start_date} åˆ° {end_date}")

        # éªŒè¯åŒæ­¥è¡Œä¸º
        self._verify_sync_behavior(start_date, end_date)

        # 4. æ£€æŸ¥æ•°æ®è´¨é‡æƒ…å†µ
        quality_stats = self._analyze_data_quality(db_manager, test_symbol)

        # éªŒè¯å†å²æ•°æ®å¤„ç†é€»è¾‘
        self._verify_historical_data_logic(quality_stats)

    def test_sync_range_after_data_deletion(
        self, db_manager, data_source_manager, processing_engine, config
    ):
        """æµ‹è¯•åˆ é™¤æ•°æ®åçš„åŒæ­¥èŒƒå›´è®¡ç®—"""
        from simtradedata.sync import IncrementalSync

        incremental_sync = IncrementalSync(
            db_manager, data_source_manager, processing_engine, config
        )

        test_symbol = "000001.SZ"
        target_date = date(2025, 1, 24)

        self.print_test_info(
            "æ•°æ®åˆ é™¤ååŒæ­¥èŒƒå›´æµ‹è¯•", [test_symbol], date(2025, 1, 20), target_date
        )

        # è®°å½•åˆ é™¤å‰çŠ¶æ€
        original_last_date = incremental_sync.get_last_data_date(test_symbol, "1d")
        original_start, original_end = incremental_sync.calculate_sync_range(
            test_symbol, target_date, "1d"
        )

        print(f"åˆ é™¤å‰æœ€åæ•°æ®æ—¥æœŸ: {original_last_date}")
        print(f"åˆ é™¤å‰åŒæ­¥èŒƒå›´: {original_start} åˆ° {original_end}")

        # åˆ é™¤ä¸€äº›æœ€æ–°æ•°æ®
        recent_date = "2025-01-20"
        print(f"åˆ é™¤ {test_symbol} ä» {recent_date} å¼€å§‹çš„æ•°æ®...")
        db_manager.execute(
            "DELETE FROM market_data WHERE symbol = ? AND date >= ?",
            (test_symbol, recent_date),
        )

        # é‡æ–°è®¡ç®—åŒæ­¥èŒƒå›´
        new_last_date = incremental_sync.get_last_data_date(test_symbol, "1d")
        new_start_date, new_end_date = incremental_sync.calculate_sync_range(
            test_symbol, target_date, "1d"
        )

        print(f"åˆ é™¤åæœ€åæ•°æ®æ—¥æœŸ: {new_last_date}")
        print(f"åˆ é™¤ååŒæ­¥èŒƒå›´: {new_start_date} åˆ° {new_end_date}")

        # éªŒè¯åˆ é™¤æ•°æ®å¯¹åŒæ­¥èŒƒå›´çš„å½±å“
        if new_start_date:
            print(f"ğŸ”„ ç°åœ¨ä¼šåŒæ­¥ {new_start_date} åˆ° {new_end_date} çš„æ•°æ®")
            print(f"ğŸ” è¿™è¯æ˜äº†å¢é‡åŒæ­¥åªå¤„ç†ç¼ºå¤±çš„æ—¥æœŸèŒƒå›´")

            # éªŒè¯åŒæ­¥èŒƒå›´çš„åˆç†æ€§ï¼šåˆ é™¤æ•°æ®åï¼Œå¢é‡åŒæ­¥ä¼šä»æ›´æ—©æ—¥æœŸå¼€å§‹ä»¥ç¡®ä¿æ•°æ®è¿ç»­æ€§
            assert new_start_date <= date.fromisoformat(
                recent_date
            ), f"æ–°çš„åŒæ­¥èµ·å§‹æ—¥æœŸåº”è¯¥ä¸æ™šäºåˆ é™¤çš„æ—¥æœŸï¼Œä»¥ç¡®ä¿æ•°æ®è¿ç»­æ€§: {new_start_date} <= {recent_date}"
        else:
            pytest.fail("åˆ é™¤æ•°æ®ååº”è¯¥äº§ç”Ÿéœ€è¦åŒæ­¥çš„æ—¥æœŸèŒƒå›´")

    def test_null_derived_fields_behavior(self, db_manager):
        """æµ‹è¯•å¯¹NULLè¡ç”Ÿå­—æ®µçš„å¤„ç†è¡Œä¸º"""
        test_symbol = "000001.SZ"

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨NULLè¡ç”Ÿå­—æ®µçš„è®°å½•
        null_check_sql = """
        SELECT COUNT(*) as null_count
        FROM market_data 
        WHERE symbol = ? AND (change_percent IS NULL OR prev_close IS NULL)
        """

        null_result = db_manager.fetchone(null_check_sql, (test_symbol,))
        null_count = null_result["null_count"] if null_result else 0

        print(f"å‘ç° {null_count} æ¡è¡ç”Ÿå­—æ®µä¸ºNULLçš„è®°å½•")

        if null_count > 0:
            print("âš ï¸ å¢é‡åŒæ­¥ä¸ä¼šè‡ªåŠ¨è¡¥å……å†å²æ•°æ®çš„NULLè¡ç”Ÿå­—æ®µ")
            print("ğŸ” è¿™éœ€è¦ä¸“é—¨çš„æ•°æ®è¡¥å……æµç¨‹")

            # éªŒè¯è¿™æ˜¯é¢„æœŸè¡Œä¸º
            assert null_count >= 0, "NULLè¡ç”Ÿå­—æ®µæ•°é‡åº”è¯¥æ˜¯éè´Ÿæ•°"
        else:
            print("âœ… æ²¡æœ‰å‘ç°NULLè¡ç”Ÿå­—æ®µï¼Œæ•°æ®è´¨é‡è‰¯å¥½")

    def _check_current_data_state(self, db_manager, symbol):
        """æ£€æŸ¥å½“å‰æ•°æ®çŠ¶æ€"""
        print("\nğŸ“Š æ£€æŸ¥å½“å‰æ•°æ®çŠ¶æ€...")
        check_sql = """
        SELECT date, close, change_percent, prev_close, source
        FROM market_data 
        WHERE symbol = ? 
        ORDER BY date DESC 
        LIMIT 5
        """

        current_data = db_manager.fetchall(check_sql, (symbol,))

        if current_data:
            print(f"æ‰¾åˆ° {len(current_data)} æ¡æœ€æ–°è®°å½•:")
            for record in current_data:
                print(
                    f"  {record['date']}: æ”¶ç›˜{record['close']}, "
                    f"æ¶¨è·Œå¹…{record['change_percent']}%, "
                    f"æ•°æ®æº:{record['source']}"
                )
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å†å²æ•°æ®")

        return current_data

    def _verify_sync_behavior(self, start_date, end_date):
        """éªŒè¯åŒæ­¥è¡Œä¸º"""
        if start_date is None:
            print("âœ… æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œä¸ä¼šè¿›è¡ŒåŒæ­¥")
            print("ğŸ” è¿™æ„å‘³ç€å¢é‡åŒæ­¥ä¸ä¼šé‡æ–°å¤„ç†å†å²æ•°æ®")
        else:
            print(f"ğŸ”„ ä¼šåŒæ­¥ {start_date} åˆ° {end_date} çš„æ•°æ®")
            print("ğŸ” è¿™æ„å‘³ç€åªä¼šå¤„ç†æ–°å¢çš„æ—¥æœŸèŒƒå›´")

    def _analyze_data_quality(self, db_manager, symbol):
        """åˆ†ææ•°æ®è´¨é‡æƒ…å†µ"""
        print(f"\nğŸ“Š æ£€æŸ¥ {symbol} çš„æ•°æ®è´¨é‡æƒ…å†µ...")
        quality_sql = """
        SELECT 
            COUNT(*) as total_records,
            COUNT(CASE WHEN change_percent IS NULL THEN 1 END) as null_change_percent,
            COUNT(CASE WHEN source LIKE '%enhanced' THEN 1 END) as enhanced_records,
            MIN(date) as earliest_date,
            MAX(date) as latest_date
        FROM market_data 
        WHERE symbol = ?
        """

        quality_stats = db_manager.fetchone(quality_sql, (symbol,))

        if quality_stats:
            total = quality_stats["total_records"]
            print(f"  æ€»è®°å½•æ•°: {total}")

            if total > 0:
                enhanced_pct = quality_stats["enhanced_records"] / total * 100
                null_pct = quality_stats["null_change_percent"] / total * 100

                print(
                    f"  å¢å¼ºå¤„ç†è®°å½•: {quality_stats['enhanced_records']} ({enhanced_pct:.1f}%)"
                )
                print(
                    f"  change_percentä¸ºNULL: {quality_stats['null_change_percent']} ({null_pct:.1f}%)"
                )
                print(
                    f"  æ—¥æœŸèŒƒå›´: {quality_stats['earliest_date']} åˆ° {quality_stats['latest_date']}"
                )
            else:
                print("  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ•°æ®è®°å½•")

        return quality_stats

    def _verify_historical_data_logic(self, quality_stats):
        """éªŒè¯å†å²æ•°æ®å¤„ç†é€»è¾‘"""
        if quality_stats and quality_stats["null_change_percent"] > 0:
            print(
                f"âš ï¸ è¯¥è‚¡ç¥¨æœ‰ {quality_stats['null_change_percent']} æ¡å†å²è®°å½•çš„è¡ç”Ÿå­—æ®µä¸ºNULL"
            )
            print(f"ğŸ” å¢é‡åŒæ­¥ä¸ä¼šé‡æ–°å¤„ç†è¿™äº›å†å²æ•°æ®")

            # è¿™æ˜¯é¢„æœŸè¡Œä¸ºï¼Œä¸éœ€è¦æ–­è¨€å¤±è´¥
            assert quality_stats["null_change_percent"] >= 0, "NULLå­—æ®µæ•°é‡åº”è¯¥æ˜¯éè´Ÿæ•°"
        else:
            print(f"âœ… è¯¥è‚¡ç¥¨çš„æ‰€æœ‰è¡ç”Ÿå­—æ®µéƒ½å·²è®¡ç®—å®Œæˆ")


@pytest.mark.sync
@pytest.mark.integration
class TestHistoricalDataConclusions(BaseTestClass):
    """å†å²æ•°æ®å¤„ç†è¡Œä¸ºç»“è®ºæµ‹è¯•"""

    def test_historical_data_processing_principles(self):
        """æµ‹è¯•å†å²æ•°æ®å¤„ç†çš„åŸºæœ¬åŸåˆ™"""
        self.print_test_info(
            "å†å²æ•°æ®å¤„ç†åŸåˆ™éªŒè¯", [], date(2025, 1, 1), date(2025, 1, 31)
        )

        # éªŒè¯å¢é‡åŒæ­¥çš„è®¾è®¡åŸåˆ™
        principles = {
            "only_missing_dates": "å¢é‡åŒæ­¥åªå¤„ç†ç¼ºå¤±çš„æ—¥æœŸèŒƒå›´",
            "no_reprocess_existing": "å·²å­˜åœ¨çš„å†å²æ•°æ®ä¸ä¼šè¢«é‡æ–°å¤„ç†",
            "null_fields_remain": "å†å²æ•°æ®çš„NULLè¡ç”Ÿå­—æ®µä¸ä¼šè‡ªåŠ¨è¡¥å……",
            "deletion_triggers_sync": "åˆ é™¤æ•°æ®åä¼šè§¦å‘ç›¸åº”èŒƒå›´çš„é‡æ–°åŒæ­¥",
        }

        print("\nğŸ“‹ å¢é‡åŒæ­¥çš„è®¾è®¡åŸåˆ™:")
        for key, principle in principles.items():
            print(f"âœ… {principle}")

        # è¿™äº›åŸåˆ™åæ˜ äº†å¢é‡åŒæ­¥çš„é«˜æ•ˆè®¾è®¡
        assert len(principles) == 4, "åº”è¯¥æœ‰4ä¸ªæ ¸å¿ƒè®¾è®¡åŸåˆ™"

        print("\nğŸ¯ è¦è¡¥å……å†å²æ•°æ®çš„NULLå­—æ®µï¼Œæ¨èæ–¹æ³•:")
        print("1ï¸âƒ£ åˆ é™¤ç›¸å…³å†å²æ•°æ®åé‡æ–°åŒæ­¥")
        print("2ï¸âƒ£ ä½¿ç”¨ä¸“é—¨çš„æ•°æ®è¡¥å……è„šæœ¬")
        print("3ï¸âƒ£ è¿è¡Œå…¨é‡æ•°æ®é‡å»ºæµç¨‹")

        print("\nâœ… å†å²æ•°æ®å¤„ç†åŸåˆ™éªŒè¯å®Œæˆ")
