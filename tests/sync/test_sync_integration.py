"""
åŒæ­¥ç³»ç»ŸåŠŸèƒ½å®Œæ•´é›†æˆæµ‹è¯•

æµ‹è¯•æ•°æ®åŒæ­¥ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬å¢é‡åŒæ­¥ã€ç¼ºå£æ£€æµ‹ã€
æ•°æ®éªŒè¯ã€åŒæ­¥ç®¡ç†ã€é”™è¯¯æ¢å¤ç­‰å…¨æ–¹ä½åŠŸèƒ½ã€‚
ä½¿ç”¨çœŸå®çš„é¡¹ç›®ç»„ä»¶è¿›è¡Œæµ‹è¯•ã€‚
"""

import logging
import tempfile
import time
from datetime import date, timedelta
from pathlib import Path

import pytest

from simtradedata.config import Config
from simtradedata.data_sources import DataSourceManager
from simtradedata.database import DatabaseManager
from simtradedata.preprocessor import DataProcessingEngine
from simtradedata.sync import DataValidator, GapDetector, IncrementalSync, SyncManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@pytest.fixture
def temp_sync_db():
    """åˆ›å»ºä¸´æ—¶åŒæ­¥æµ‹è¯•æ•°æ®åº“"""
    with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
        db_path = f.name

    config = Config()
    db_manager = DatabaseManager(db_path, config=config)

    # åˆ›å»ºå¿…è¦çš„æµ‹è¯•è¡¨
    _create_sync_test_tables(db_manager)

    # æ’å…¥åŸºç¡€æµ‹è¯•æ•°æ®
    _insert_sync_test_data(db_manager)

    yield db_manager

    # æ¸…ç†
    db_manager.close()
    Path(db_path).unlink(missing_ok=True)


def _create_sync_test_tables(db_manager):
    """åˆ›å»ºåŒæ­¥æµ‹è¯•æ‰€éœ€çš„è¡¨"""
    # åˆ›å»ºè‚¡ç¥¨ä¿¡æ¯è¡¨ - ä½¿ç”¨æ­£ç¡®çš„è¡¨å
    db_manager.execute(
        """
        CREATE TABLE IF NOT EXISTS stocks (
            symbol TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            market TEXT NOT NULL,
            status TEXT DEFAULT 'active',
            list_date DATE,
            industry_l1 TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """
    )

    # åˆ›å»ºå¸‚åœºæ•°æ®è¡¨ - ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
    db_manager.execute(
        """
        CREATE TABLE IF NOT EXISTS market_data (
            symbol TEXT NOT NULL,
            date DATE NOT NULL,
            frequency TEXT NOT NULL DEFAULT '1d',
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume REAL,
            amount REAL,
            prev_close REAL,
            change_percent REAL,
            turnover_rate REAL,
            quality_score INTEGER DEFAULT 100,
            source TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (symbol, date, frequency)
        )
    """
    )

    # åˆ›å»ºäº¤æ˜“æ—¥å†è¡¨ - ä½¿ç”¨æ­£ç¡®çš„è¡¨å
    db_manager.execute(
        """
        CREATE TABLE IF NOT EXISTS trading_calendar (
            date DATE NOT NULL,
            market TEXT NOT NULL,
            is_trading BOOLEAN NOT NULL,
            PRIMARY KEY (date, market)
        )
    """
    )

    # åˆ›å»ºåŒæ­¥çŠ¶æ€è¡¨ - ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
    db_manager.execute(
        """
        CREATE TABLE IF NOT EXISTS sync_status (
            symbol TEXT NOT NULL,
            frequency TEXT NOT NULL,
            last_sync_date DATE,
            last_data_date DATE,
            status TEXT DEFAULT 'pending',
            error_message TEXT,
            total_records INTEGER DEFAULT 0,
            last_update TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (symbol, frequency)
        )
    """
    )


def _insert_sync_test_data(db_manager):
    """æ’å…¥åŒæ­¥æµ‹è¯•æ•°æ®"""
    # æ’å…¥è‚¡ç¥¨ä¿¡æ¯ - ä½¿ç”¨æ­£ç¡®çš„è¡¨åå’Œå­—æ®µå
    stocks = [
        ("000001.SZ", "å¹³å®‰é“¶è¡Œ", "SZ", "active", "1991-04-03", "é“¶è¡Œ"),
        ("000002.SZ", "ä¸‡ç§‘A", "SZ", "active", "1991-01-29", "æˆ¿åœ°äº§"),
        ("600000.SS", "æµ¦å‘é“¶è¡Œ", "SS", "active", "1999-11-10", "é“¶è¡Œ"),
    ]

    db_manager.executemany(
        "INSERT OR REPLACE INTO stocks (symbol, name, market, status, list_date, industry_l1) VALUES (?, ?, ?, ?, ?, ?)",
        stocks,
    )

    # æ’å…¥äº¤æ˜“æ—¥å†æ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼šå·¥ä½œæ—¥ä¸ºäº¤æ˜“æ—¥ï¼‰
    start_date = date(2024, 1, 1)
    for i in range(60):  # 2ä¸ªæœˆçš„æ—¥å†
        current_date = start_date + timedelta(days=i)
        is_trading = current_date.weekday() < 5  # å‘¨ä¸€åˆ°å‘¨äº”

        db_manager.execute(
            "INSERT OR REPLACE INTO trading_calendar (date, market, is_trading) VALUES (?, ?, ?)",
            (str(current_date), "CN", is_trading),
        )

    # æ’å…¥ä¸€äº›å†å²æ•°æ®ï¼ˆæœ‰æ„ç•™ä¸€äº›ç¼ºå£ç”¨äºæµ‹è¯•ï¼‰- ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
    market_data = [
        (
            "000001.SZ",
            "2024-01-15",
            "1d",
            10.0,
            10.5,
            9.8,
            10.2,
            1000000,
            10200000,
            10.0,
            2.0,
            5.5,
            95,
            "test",
        ),
        (
            "000001.SZ",
            "2024-01-16",
            "1d",
            10.2,
            10.8,
            10.0,
            10.5,
            1200000,
            12600000,
            10.2,
            2.9,
            6.2,
            90,
            "test",
        ),
        # æ•…æ„è·³è¿‡ 2024-01-17 åˆ›å»ºç¼ºå£
        (
            "000001.SZ",
            "2024-01-18",
            "1d",
            10.5,
            11.0,
            10.3,
            10.8,
            1500000,
            16200000,
            10.5,
            2.9,
            7.8,
            85,
            "test",
        ),
        (
            "000002.SZ",
            "2024-01-15",
            "1d",
            8.0,
            8.3,
            7.8,
            8.1,
            800000,
            6480000,
            8.0,
            1.3,
            4.2,
            92,
            "test",
        ),
        (
            "000002.SZ",
            "2024-01-16",
            "1d",
            8.1,
            8.5,
            7.9,
            8.3,
            900000,
            7470000,
            8.1,
            2.5,
            4.8,
            88,
            "test",
        ),
    ]

    db_manager.executemany(
        "INSERT OR REPLACE INTO market_data (symbol, date, frequency, open, high, low, close, volume, amount, prev_close, change_percent, turnover_rate, quality_score, source) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
        market_data,
    )


@pytest.mark.integration
class TestSyncSystemIntegration:
    """åŒæ­¥ç³»ç»Ÿé›†æˆæµ‹è¯•"""

    def test_incremental_sync_basic_functionality(self, temp_sync_db):
        """æµ‹è¯•å¢é‡åŒæ­¥åŸºæœ¬åŠŸèƒ½"""
        logger.info("ğŸ§ª æµ‹è¯•å¢é‡åŒæ­¥åŸºæœ¬åŠŸèƒ½...")

        config = Config()
        data_source_manager = DataSourceManager(config)
        processing_engine = DataProcessingEngine(temp_sync_db, config)

        # åˆ›å»ºå¢é‡åŒæ­¥å™¨
        incremental_sync = IncrementalSync(
            temp_sync_db, data_source_manager, processing_engine, config
        )

        # æµ‹è¯•è·å–æœ€åæ•°æ®æ—¥æœŸ
        last_date = incremental_sync.get_last_data_date("000001.SZ", "1d")
        assert last_date == date(2024, 1, 18)  # æœ€æ–°çš„æ•°æ®æ—¥æœŸ

        # æµ‹è¯•è®¡ç®—åŒæ­¥èŒƒå›´
        start_date, end_date = incremental_sync.calculate_sync_range(
            "000001.SZ", date(2024, 1, 20)
        )
        assert start_date == date(2024, 1, 19)  # æœ€åæ—¥æœŸçš„ä¸‹ä¸€å¤©
        assert end_date == date(2024, 1, 20)

        # æµ‹è¯•æ— å†å²æ•°æ®çš„è‚¡ç¥¨
        last_date_new = incremental_sync.get_last_data_date("999999.SZ", "1d")
        assert last_date_new is None

        # æµ‹è¯•è·å–æ´»è·ƒè‚¡ç¥¨åˆ—è¡¨
        stats = incremental_sync.get_sync_stats()
        assert isinstance(stats, dict)

        logger.info("âœ… å¢é‡åŒæ­¥åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")

    def test_gap_detector_functionality(self, temp_sync_db):
        """æµ‹è¯•ç¼ºå£æ£€æµ‹å™¨åŠŸèƒ½"""
        logger.info("ğŸ§ª æµ‹è¯•ç¼ºå£æ£€æµ‹å™¨åŠŸèƒ½...")

        config = Config()
        gap_detector = GapDetector(temp_sync_db, config)

        # æ£€æµ‹000001.SZçš„ç¼ºå£ï¼ˆæˆ‘ä»¬æ•…æ„è·³è¿‡äº†2024-01-17ï¼‰
        gaps = gap_detector.detect_symbol_gaps(
            "000001.SZ", date(2024, 1, 15), date(2024, 1, 18), "1d"
        )

        # åº”è¯¥æ£€æµ‹åˆ°2024-01-17çš„ç¼ºå£
        assert len(gaps) > 0

        # æ£€æŸ¥ç¼ºå£ç±»å‹
        date_gaps = [gap for gap in gaps if gap["gap_type"] == "date_missing"]
        assert len(date_gaps) > 0

        # æ£€æŸ¥å…·ä½“çš„ç¼ºå£æ—¥æœŸ - ä¿®å¤å­—æ®µè®¿é—®
        gap_found = False
        for gap in date_gaps:
            if "2024-01-17" in gap["start_date"] or "2024-01-17" in gap["end_date"]:
                gap_found = True
                break

        assert gap_found, f"æœªæ‰¾åˆ°2024-01-17çš„ç¼ºå£ï¼Œå®é™…ç¼ºå£: {date_gaps}"

        logger.info(f"æ£€æµ‹åˆ°ç¼ºå£: {date_gaps}")
        logger.info("âœ… ç¼ºå£æ£€æµ‹å™¨åŠŸèƒ½æµ‹è¯•é€šè¿‡")

    def test_data_validator_functionality(self, temp_sync_db):
        """æµ‹è¯•æ•°æ®éªŒè¯å™¨åŠŸèƒ½"""
        logger.info("ğŸ§ª æµ‹è¯•æ•°æ®éªŒè¯å™¨åŠŸèƒ½...")

        # æ’å…¥ä¸€äº›å¼‚å¸¸æ•°æ®ç”¨äºæµ‹è¯• - ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
        problematic_data = [
            # å¼‚å¸¸æ•°æ®ï¼šå¼€ç›˜ä»·ä¸º0
            (
                "600000.SS",
                "2024-01-15",
                "1d",
                0.0,
                12.5,
                11.8,
                12.2,
                1000000,
                12200000,
                12.0,
                1.7,
                4.5,
                30,
                "test",
            ),
            # å¼‚å¸¸æ•°æ®ï¼šè´Ÿæˆäº¤é‡
            (
                "600000.SS",
                "2024-01-16",
                "1d",
                12.2,
                12.8,
                12.0,
                12.5,
                -500000,
                12500000,
                12.2,
                2.5,
                4.8,
                20,
                "test",
            ),
            # æ­£å¸¸æ•°æ®
            (
                "600000.SS",
                "2024-01-17",
                "1d",
                12.5,
                13.0,
                12.3,
                12.8,
                1100000,
                14080000,
                12.5,
                2.4,
                5.2,
                95,
                "test",
            ),
        ]

        temp_sync_db.executemany(
            "INSERT OR REPLACE INTO market_data (symbol, date, frequency, open, high, low, close, volume, amount, prev_close, change_percent, turnover_rate, quality_score, source) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
            problematic_data,
        )

        config = Config()
        validator = DataValidator(temp_sync_db, config)

        # éªŒè¯æ•°æ®
        validation_result = validator.validate_symbol_data(
            "600000.SS", date(2024, 1, 15), date(2024, 1, 17), "1d"
        )

        # éªŒè¯ç»“æœ
        assert validation_result["symbol"] == "600000.SS"
        assert validation_result["total_records"] == 3
        assert validation_result["invalid_records"] >= 2  # åº”è¯¥æ£€æµ‹åˆ°è‡³å°‘2æ¡å¼‚å¸¸æ•°æ®
        assert len(validation_result["issues"]) >= 2

        logger.info(
            f"éªŒè¯ç»“æœ: æ€»è®°å½•{validation_result['total_records']}, å¼‚å¸¸è®°å½•{validation_result['invalid_records']}, é—®é¢˜{len(validation_result['issues'])}ä¸ª"
        )
        logger.info("âœ… æ•°æ®éªŒè¯å™¨åŠŸèƒ½æµ‹è¯•é€šè¿‡")

    def test_sync_manager_comprehensive_workflow(self, temp_sync_db):
        """æµ‹è¯•åŒæ­¥ç®¡ç†å™¨ç»¼åˆå·¥ä½œæµç¨‹"""
        logger.info("ğŸ§ª æµ‹è¯•åŒæ­¥ç®¡ç†å™¨ç»¼åˆå·¥ä½œæµç¨‹...")

        config = Config()
        data_source_manager = DataSourceManager(config)
        processing_engine = DataProcessingEngine(temp_sync_db, config)

        # åˆ›å»ºåŒæ­¥ç®¡ç†å™¨
        sync_manager = SyncManager(
            temp_sync_db, data_source_manager, processing_engine, config
        )

        # æµ‹è¯•è·å–åŒæ­¥çŠ¶æ€
        status_response = sync_manager.get_sync_status()
        assert status_response["success"] == True
        assert "recent_syncs" in status_response["data"]
        assert "data_stats" in status_response["data"]

        # éªŒè¯æ•°æ®ç»Ÿè®¡
        data_stats = status_response["data"]["data_stats"]
        assert data_stats["total_records"] > 0  # æˆ‘ä»¬æ’å…¥äº†æµ‹è¯•æ•°æ®
        assert data_stats["total_symbols"] >= 2  # è‡³å°‘æœ‰2ä¸ªè‚¡ç¥¨æœ‰æ•°æ®

        logger.info(f"åŒæ­¥çŠ¶æ€: {status_response['data']['data_stats']}")
        logger.info("âœ… åŒæ­¥ç®¡ç†å™¨ç»¼åˆå·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")

    def test_database_operations(self, temp_sync_db):
        """æµ‹è¯•æ•°æ®åº“æ“ä½œ"""
        logger.info("ğŸ§ª æµ‹è¯•æ•°æ®åº“æ“ä½œ...")

        # æµ‹è¯•æŸ¥è¯¢è‚¡ç¥¨ä¿¡æ¯ - ä½¿ç”¨æ­£ç¡®çš„è¡¨å
        stocks = temp_sync_db.fetchall("SELECT * FROM stocks")
        assert len(stocks) >= 3

        # æµ‹è¯•æŸ¥è¯¢å¸‚åœºæ•°æ®
        market_data = temp_sync_db.fetchall("SELECT * FROM market_data")
        assert len(market_data) >= 5

        # æµ‹è¯•æŸ¥è¯¢äº¤æ˜“æ—¥å† - ä½¿ç”¨æ­£ç¡®çš„è¡¨å
        calendar_data = temp_sync_db.fetchall(
            "SELECT * FROM trading_calendar WHERE date BETWEEN ? AND ?",
            ("2024-01-15", "2024-01-20"),
        )
        assert len(calendar_data) > 0

        # æµ‹è¯•æ•°æ®å®Œæ•´æ€§
        for stock in stocks:
            assert stock["symbol"] is not None
            assert stock["name"] is not None
            assert stock["market"] is not None

        for data in market_data:
            assert data["symbol"] is not None
            assert data["date"] is not None  # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
            assert data["close"] is not None

        logger.info("âœ… æ•°æ®åº“æ“ä½œæµ‹è¯•é€šè¿‡")

    def test_sync_error_handling(self, temp_sync_db):
        """æµ‹è¯•åŒæ­¥é”™è¯¯å¤„ç†"""
        logger.info("ğŸ§ª æµ‹è¯•åŒæ­¥é”™è¯¯å¤„ç†...")

        config = Config()
        data_source_manager = DataSourceManager(config)
        processing_engine = DataProcessingEngine(temp_sync_db, config)

        # åˆ›å»ºå¢é‡åŒæ­¥å™¨
        incremental_sync = IncrementalSync(
            temp_sync_db, data_source_manager, processing_engine, config
        )

        # æµ‹è¯•ä¸å­˜åœ¨çš„è‚¡ç¥¨
        last_date = incremental_sync.get_last_data_date("INVALID.SZ", "1d")
        assert last_date is None

        # æµ‹è¯•æ— æ•ˆæ—¥æœŸèŒƒå›´
        start_date, end_date = incremental_sync.calculate_sync_range(
            "INVALID.SZ", date(2024, 1, 20)
        )
        # åº”è¯¥è¿”å›é»˜è®¤èŒƒå›´æˆ–None
        assert end_date == date(2024, 1, 20)

        logger.info("âœ… åŒæ­¥é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

    def test_performance_basic(self, temp_sync_db):
        """æµ‹è¯•åŸºæœ¬æ€§èƒ½"""
        logger.info("ğŸ§ª æµ‹è¯•åŸºæœ¬æ€§èƒ½...")

        # æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
        start_time = time.time()

        # æ‰§è¡Œå¤æ‚æŸ¥è¯¢ - ä½¿ç”¨æ­£ç¡®çš„è¡¨åå’Œå­—æ®µå
        result = temp_sync_db.fetchall(
            """
            SELECT 
                s.symbol,
                s.name,
                COUNT(m.date) as data_days,
                AVG(m.close) as avg_close,
                MAX(m.high) as max_high,
                MIN(m.low) as min_low
            FROM stocks s
            LEFT JOIN market_data m ON s.symbol = m.symbol
            WHERE s.status = 'active'
            GROUP BY s.symbol, s.name
            ORDER BY data_days DESC
        """
        )

        end_time = time.time()
        query_time = end_time - start_time

        logger.info(f"å¤æ‚æŸ¥è¯¢è€—æ—¶: {query_time:.3f}ç§’")
        logger.info(f"æŸ¥è¯¢ç»“æœæ¡æ•°: {len(result)}")

        # åŸºæœ¬æ€§èƒ½è¦æ±‚
        assert query_time < 1.0  # æŸ¥è¯¢åº”åœ¨1ç§’å†…å®Œæˆ
        assert len(result) > 0

        logger.info("âœ… åŸºæœ¬æ€§èƒ½æµ‹è¯•é€šè¿‡")


@pytest.mark.integration
def test_sync_system_full_integration():
    """åŒæ­¥ç³»ç»Ÿå®Œæ•´é›†æˆæµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹åŒæ­¥ç³»ç»Ÿå®Œæ•´é›†æˆæµ‹è¯•...")

    # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
    with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
        db_path = f.name

    try:
        config = Config()
        db_manager = DatabaseManager(db_path, config=config)

        # åˆ›å»ºå®Œæ•´çš„è¡¨ç»“æ„
        _create_sync_test_tables(db_manager)
        _insert_sync_test_data(db_manager)

        # åˆ›å»ºç»„ä»¶
        data_source_manager = DataSourceManager(config)
        processing_engine = DataProcessingEngine(db_manager, config)

        # æµ‹è¯•å¢é‡åŒæ­¥å™¨
        incremental_sync = IncrementalSync(
            db_manager, data_source_manager, processing_engine, config
        )

        # æµ‹è¯•è·å–æœ€åæ•°æ®æ—¥æœŸ
        last_date = incremental_sync.get_last_data_date("000001.SZ", "1d")
        assert last_date == date(2024, 1, 18)

        # æµ‹è¯•è®¡ç®—åŒæ­¥èŒƒå›´
        start_date, end_date = incremental_sync.calculate_sync_range(
            "000001.SZ", date(2024, 1, 20)
        )
        assert start_date == date(2024, 1, 19)
        assert end_date == date(2024, 1, 20)

        # æµ‹è¯•ç¼ºå£æ£€æµ‹å™¨
        gap_detector = GapDetector(db_manager, config)
        gaps = gap_detector.detect_symbol_gaps(
            "000001.SZ", date(2024, 1, 15), date(2024, 1, 18), "1d"
        )
        assert len(gaps) > 0  # åº”è¯¥æ£€æµ‹åˆ°2024-01-17çš„ç¼ºå£

        # æµ‹è¯•æ•°æ®éªŒè¯å™¨
        validator = DataValidator(db_manager, config)

        # æ’å…¥ä¸€äº›å¼‚å¸¸æ•°æ®è¿›è¡ŒéªŒè¯æµ‹è¯• - ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
        db_manager.execute(
            "INSERT OR REPLACE INTO market_data (symbol, date, frequency, open, high, low, close, volume, amount, prev_close, change_percent, turnover_rate, quality_score, source) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
            (
                "TEST.SZ",
                "2024-01-15",
                "1d",
                0.0,
                10.5,
                9.5,
                10.0,
                -1000,
                10000,
                10.0,
                0.0,
                0.0,
                10,
                "test",
            ),
        )

        validation_result = validator.validate_symbol_data(
            "TEST.SZ", date(2024, 1, 15), date(2024, 1, 15), "1d"
        )
        assert validation_result["symbol"] == "TEST.SZ"
        assert validation_result["invalid_records"] > 0  # å¼‚å¸¸æ•°æ®

        # æµ‹è¯•åŒæ­¥ç®¡ç†å™¨
        sync_manager = SyncManager(
            db_manager, data_source_manager, processing_engine, config
        )

        # æµ‹è¯•è·å–åŒæ­¥çŠ¶æ€
        status = sync_manager.get_sync_status()
        assert status["success"] == True
        assert status["data"]["data_stats"]["total_records"] > 0

        # éªŒè¯æœ€ç»ˆæ•°æ®åº“çŠ¶æ€ - ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
        final_stats = db_manager.fetchone(
            """
            SELECT 
                COUNT(DISTINCT symbol) as total_symbols,
                COUNT(*) as total_records,
                MIN(date) as earliest_date,
                MAX(date) as latest_date
            FROM market_data
        """
        )

        logger.info(f"æœ€ç»ˆæ•°æ®åº“ç»Ÿè®¡: {dict(final_stats)}")

        assert final_stats["total_symbols"] >= 3
        assert final_stats["total_records"] > 0

        logger.info("ğŸ‰ åŒæ­¥ç³»ç»Ÿå®Œæ•´é›†æˆæµ‹è¯•é€šè¿‡!")

    finally:
        # æ¸…ç†
        if "db_manager" in locals():
            db_manager.close()
        Path(db_path).unlink(missing_ok=True)


if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´é›†æˆæµ‹è¯•
    test_sync_system_full_integration()

    # è¿è¡Œpytestæµ‹è¯•
    pytest.main([__file__, "-v"])
